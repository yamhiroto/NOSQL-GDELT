{"paragraphs":[{"text":"%md\n## Exploration des donnees GDELT via Spark\nDans ce notebook nous allons commencer a explorer les donnees GDELT qu'on a stoque sur S3","dateUpdated":"2020-01-16T19:39:33+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Exploration des donnees GDELT via Spark</h2>\n<p>Dans ce notebook nous allons commencer a explorer les donnees GDELT qu&rsquo;on a stoque sur S3</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1579203573929_233651068","id":"20181212-102323_67420128","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4216"},{"text":"%md\n","dateUpdated":"2020-01-16T19:39:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579203573930_234805315","id":"20200115-201642_1185871106","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4217"},{"text":"%md Les fichiers sont stoquees compresses, on a besoin d'un bout de code pour les decompresser en parallel sur les workers au fur et a mesure qu'on les lit depuis S3:","dateUpdated":"2020-01-16T19:39:33+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Les fichiers sont stoquees compresses, on a besoin d&rsquo;un bout de code pour les decompresser en parallel sur les workers au fur et a mesure qu&rsquo;on les lit depuis S3:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1579203573930_234805315","id":"20181212-102329_808049084","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4218"},{"text":"%md\n","dateUpdated":"2020-01-16T19:39:33+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579203573931_234420566","id":"20200114-144519_754603050","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4219"},{"text":"import spark.implicits._\nimport org.apache.spark.sql.functions._","user":"anonymous","dateUpdated":"2020-01-16T19:41:15+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import spark.implicits._\nimport org.apache.spark.sql.functions._\n"}]},"apps":[],"jobName":"paragraph_1579203573932_232496822","id":"20200111-162130_782083733","dateCreated":"2020-01-16T19:39:33+0000","dateStarted":"2020-01-16T19:41:15+0000","dateFinished":"2020-01-16T19:41:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4220"},{"text":"%md\n### EVENT","dateUpdated":"2020-01-16T19:39:33+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>EVENT</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1579203573933_232112073","id":"20200111-162721_1795268925","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4221"},{"text":"import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\n// 20181201000000.export.CSV.zip\nval textRDD = sc.binaryFiles(\"/tmp/20181201[0-9]*.export.CSV.zip\"). // charger quelques fichers via une regex\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n","user":"anonymous","dateUpdated":"2020-01-16T19:41:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\ntextRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[70] at flatMap at <console>:51\n"}]},"apps":[],"jobName":"paragraph_1579203573936_243269791","id":"20200113-140431_2051607335","dateCreated":"2020-01-16T19:39:33+0000","dateStarted":"2020-01-16T19:41:18+0000","dateFinished":"2020-01-16T19:41:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4222"},{"text":"import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\n\n// 20181201000000.export.CSV.zip\n\n//exporter fichiers issus de masterfilelist.txt\nval textRDD_eng = sc.binaryFiles(\"/zeppelin/tmp/20181201[0-9]*.export.CSV.zip\"). // charger quelques fichers via une regex   \n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n    \n//exporter fichiers issus de masterfilelist-translation.txt\nval textRDD_translate = sc.binaryFiles(\"/zeppelin/tmp/20181201[0-9]*.translation.export.CSV.zip\"). \n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n    \n\n//concaténer les RDD et transformer en DataFrame                           //Pour des raisons de cohérence, nous indiquons ici le nom des colonnes comme indiqué dans la documentation GDELT. Nous les renommerons lorsque nécessaire plus bas\nval eventDF = textRDD_eng.union(textRDD_translate).toDF()\n.withColumn(\"GLOBALEVENTID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"Day\", split($\"value\", \"\\\\t\").getItem(1))\n.withColumn(\"MonthYear\", split($\"value\", \"\\\\t\").getItem(2))\n.withColumn(\"Year\", split($\"value\", \"\\\\t\").getItem(3))\n.withColumn(\"FractionDate\", split($\"value\", \"\\\\t\").getItem(4))\n.withColumn(\"Actor1Code\", split($\"value\", \"\\\\t\").getItem(5))\n.withColumn(\"Actor1Name\", split($\"value\", \"\\\\t\").getItem(6))\n.withColumn(\"Actor1CountryCode\", split($\"value\", \"\\\\t\").getItem(7))\n.withColumn(\"Actor1KnownGroupCode\", split($\"value\", \"\\\\t\").getItem(8))\n.withColumn(\"Actor1EthnicCode\", split($\"value\", \"\\\\t\").getItem(9))\n.withColumn(\"Actor1Religion1Code\", split($\"value\", \"\\\\t\").getItem(10))\n.withColumn(\"Actor1Religion2Code\", split($\"value\", \"\\\\t\").getItem(11))\n.withColumn(\"Actor1Type1Code\", split($\"value\", \"\\\\t\").getItem(12))\n.withColumn(\"Actor1Type2Code\", split($\"value\", \"\\\\t\").getItem(13))\n.withColumn(\"Actor1Type3Code\", split($\"value\", \"\\\\t\").getItem(14))\n.withColumn(\"Actor2Code\", split($\"value\", \"\\\\t\").getItem(15))\n.withColumn(\"Actor2Name\", split($\"value\", \"\\\\t\").getItem(16))\n.withColumn(\"Actor2CountryCode\", split($\"value\", \"\\\\t\").getItem(17))\n.withColumn(\"Actor2KnownGroupCode\", split($\"value\", \"\\\\t\").getItem(18))\n.withColumn(\"Actor2EthnicCode\", split($\"value\", \"\\\\t\").getItem(19))\n.withColumn(\"Actor2Religion1Code\", split($\"value\", \"\\\\t\").getItem(20))\n.withColumn(\"Actor2Religion2Code\", split($\"value\", \"\\\\t\").getItem(21))\n.withColumn(\"Actor2Type1Code\", split($\"value\", \"\\\\t\").getItem(22))\n.withColumn(\"Actor2Type2Code\", split($\"value\", \"\\\\t\").getItem(23))\n.withColumn(\"Actor2Type3Code\", split($\"value\", \"\\\\t\").getItem(24))\n.withColumn(\"IsRootEvent\", split($\"value\", \"\\\\t\").getItem(25))\n.withColumn(\"EventCode\", split($\"value\", \"\\\\t\").getItem(26))\n.withColumn(\"EventBaseCode\", split($\"value\", \"\\\\t\").getItem(27))\n.withColumn(\"EventRootCode\", split($\"value\", \"\\\\t\").getItem(28))\n.withColumn(\"QuadClass\", split($\"value\", \"\\\\t\").getItem(29))\n.withColumn(\"GoldsteinScale\", split($\"value\", \"\\\\t\").getItem(30))\n.withColumn(\"NumMentions\", split($\"value\", \"\\\\t\").getItem(31))\n.withColumn(\"NumSources\", split($\"value\", \"\\\\t\").getItem(32))\n.withColumn(\"NumArticles\", split($\"value\", \"\\\\t\").getItem(33))\n.withColumn(\"AvgTone\", split($\"value\", \"\\\\t\").getItem(34))\n.withColumn(\"Actor1Geo_Type\", split($\"value\", \"\\\\t\").getItem(35))\n.withColumn(\"Actor1Geo_FullName\", split($\"value\", \"\\\\t\").getItem(36))\n.withColumn(\"Actor1Geo_CountryCode\", split($\"value\", \"\\\\t\").getItem(37))\n.withColumn(\"Actor1Geo_ADM1Code\", split($\"value\", \"\\\\t\").getItem(38))\n.withColumn(\"Actor1Geo_ADM2Code\", split($\"value\", \"\\\\t\").getItem(39))\n.withColumn(\"Actor1Geo_Lat\", split($\"value\", \"\\\\t\").getItem(40))\n.withColumn(\"Actor1Geo_Long\", split($\"value\", \"\\\\t\").getItem(41))\n.withColumn(\"Actor1Geo_FeatureID\", split($\"value\", \"\\\\t\").getItem(42))\n.withColumn(\"Actor2Geo_Type\", split($\"value\", \"\\\\t\").getItem(43))\n.withColumn(\"Actor2Geo_FullName\", split($\"value\", \"\\\\t\").getItem(44))\n.withColumn(\"Actor2Geo_CountryCode\", split($\"value\", \"\\\\t\").getItem(45))\n.withColumn(\"Actor2Geo_ADM1Code\", split($\"value\", \"\\\\t\").getItem(46))\n.withColumn(\"Actor2Geo_ADM2Code\", split($\"value\", \"\\\\t\").getItem(47))\n.withColumn(\"Actor2Geo_Lat\", split($\"value\", \"\\\\t\").getItem(48))\n.withColumn(\"Actor2Geo_Long\", split($\"value\", \"\\\\t\").getItem(49))\n.withColumn(\"Actor2Geo_FeatureID\", split($\"value\", \"\\\\t\").getItem(50))\n.withColumn(\"ActionGeo_Type\", split($\"value\", \"\\\\t\").getItem(51))\n.withColumn(\"ActionGeo_FullName\", split($\"value\", \"\\\\t\").getItem(52))\n.withColumn(\"ActionGeo_CountryCode\", split($\"value\", \"\\\\t\").getItem(53))\n.withColumn(\"ActionGeo_ADM1Code\", split($\"value\", \"\\\\t\").getItem(54))\n.withColumn(\"ActionGeo_ADM2Code\", split($\"value\", \"\\\\t\").getItem(55))\n.withColumn(\"ActionGeo_Lat\", split($\"value\", \"\\\\t\").getItem(56))\n.withColumn(\"ActionGeo_Long\", split($\"value\", \"\\\\t\").getItem(57))\n.withColumn(\"ActionGeo_FeatureID\", split($\"value\", \"\\\\t\").getItem(58))\n.withColumn(\"DATEADDED\", split($\"value\", \"\\\\t\").getItem(59))\n.withColumn(\"SOURCEURL\", split($\"value\", \"\\\\t\").getItem(60))\n.drop($\"value\")\n","dateUpdated":"2020-01-16T20:34:39+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":195.994,"optionOpen":false}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\ntextRDD_eng: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[72] at flatMap at <console>:55\ntextRDD_translate: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[74] at flatMap at <console>:55\neventDF: org.apache.spark.sql.DataFrame = [GLOBALEVENTID: string, Day: string ... 59 more fields]\n"}]},"apps":[],"jobName":"paragraph_1579203573937_242885042","id":"20171217-232457_1732696781","dateCreated":"2020-01-16T19:39:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4223","user":"anonymous","dateFinished":"2020-01-16T19:45:58+0000","dateStarted":"2020-01-16T19:45:51+0000"},{"text":"%md\n### GLOBAL KNOWLEDGE GRAPH","dateUpdated":"2020-01-16T19:39:33+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>GLOBAL KNOWLEDGE GRAPH</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1579203573938_244039289","id":"20200111-162229_916549909","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4224"},{"text":"//exporter fichiers issus de masterfilelist.txt\nval gkgRDD_eng = sc.binaryFiles(\"/zeppelin/tmp/20181201[0-9]*.gkg.csv.zip\"). // charger quelques fichers via une regex   \n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n\n//exporter fichiers issus de masterfilelist-translation.txt\nval gkgRDD_translate = sc.binaryFiles(\"/zeppelin/tmp/20181201[0-9]*.translation.gkg.csv.zip\").  \n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n    \n//concaténer les RDD et transformer en DataFrame                                    \nval gkgDF = gkgRDD_eng.union(gkgRDD_translate).toDF()\n.withColumn(\"GKGRECORDID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"DATE\", split($\"value\", \"\\\\t\").getItem(1))\n.withColumn(\"SourceCollectionIdentifier\", split($\"value\", \"\\\\t\").getItem(2))\n.withColumn(\"SourceCommonName\", split($\"value\", \"\\\\t\").getItem(3))\n.withColumn(\"DocumentIdentifier\", split($\"value\", \"\\\\t\").getItem(4))\n.withColumn(\"Counts\", split($\"value\", \"\\\\t\").getItem(5))\n.withColumn(\"V2Counts\", split($\"value\", \"\\\\t\").getItem(6))\n.withColumn(\"Themes\", split($\"value\", \"\\\\t\").getItem(7))\n.withColumn(\"V2Themes\", split($\"value\", \"\\\\t\").getItem(8))\n.withColumn(\"Locations\", split($\"value\", \"\\\\t\").getItem(9))\n.withColumn(\"V2Locations\", split($\"value\", \"\\\\t\").getItem(10))\n.withColumn(\"Persons\", split($\"value\", \"\\\\t\").getItem(11))\n.withColumn(\"V2Persons\", split($\"value\", \"\\\\t\").getItem(12))\n.withColumn(\"Organizations\", split($\"value\", \"\\\\t\").getItem(13))\n.withColumn(\"V2Organizations\", split($\"value\", \"\\\\t\").getItem(14))\n.withColumn(\"V2Tone\", split($\"value\", \"\\\\t\").getItem(15))\n.withColumn(\"Dates\", split($\"value\", \"\\\\t\").getItem(16))\n.withColumn(\"GCAM\", split($\"value\", \"\\\\t\").getItem(17))\n.withColumn(\"SharingImage\", split($\"value\", \"\\\\t\").getItem(18))\n.withColumn(\"RelatedImages\", split($\"value\", \"\\\\t\").getItem(19))\n.withColumn(\"SocialImageEmbeds\", split($\"value\", \"\\\\t\").getItem(20))\n.withColumn(\"SocialVideoEmbeds\", split($\"value\", \"\\\\t\").getItem(21))\n.withColumn(\"Quotations\", split($\"value\", \"\\\\t\").getItem(22))\n.withColumn(\"AllNames\", split($\"value\", \"\\\\t\").getItem(23))\n.withColumn(\"Amounts\", split($\"value\", \"\\\\t\").getItem(24))\n.withColumn(\"TranslationInfo\", split($\"value\", \"\\\\t\").getItem(25))\n.withColumn(\"Extras\", split($\"value\", \"\\\\t\").getItem(26))\n.drop($\"value\")","dateUpdated":"2020-01-16T20:04:20+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"gkgRDD_eng: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[77] at flatMap at <console>:55\ngkgRDD_translate: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[79] at flatMap at <console>:56\ngkgDF: org.apache.spark.sql.DataFrame = [GKGRECORDID: string, DATE: string ... 25 more fields]\n"}]},"apps":[],"jobName":"paragraph_1579203573939_243654540","id":"20200111-160038_1308018681","dateCreated":"2020-01-16T19:39:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4225","user":"anonymous","dateFinished":"2020-01-16T19:53:54+0000","dateStarted":"2020-01-16T19:53:51+0000"},{"text":"%md\n### MENTION ","dateUpdated":"2020-01-16T19:39:33+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>MENTION</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1579203573940_241730795","id":"20200111-161729_1436776043","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4226"},{"text":"//exporter fichiers issus de masterfilelist.txt\nval mentionRDD_eng = sc.binaryFiles(\"/zeppelin/tmp/20181201[0-9]*.mentions.CSV.zip\").   \n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n    \n//exporter fichiers issus de masterfilelist-translation.txt\nval mentionRDD_translate = sc.binaryFiles(\"/zeppelin/tmp/20181201[0-9]*.translation.mentions.CSV.zip\"). \n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\n    \n//concaténer les RDD et transformer en DataFrame\nval mentionDF = mentionRDD_eng.union(mentionRDD_translate).toDF()\n.withColumn(\"GLOBALEVENTID\", split($\"value\", \"\\\\t\").getItem(0))\n.withColumn(\"EventTimeDate\", split($\"value\", \"\\\\t\").getItem(1))\n.withColumn(\"MentionTimeDate\", split($\"value\", \"\\\\t\").getItem(2))\n.withColumn(\"MentionType\", split($\"value\", \"\\\\t\").getItem(3))\n.withColumn(\"MentionSourceName\", split($\"value\", \"\\\\t\").getItem(4))\n.withColumn(\"MentionIdentifier\", split($\"value\", \"\\\\t\").getItem(5))\n.withColumn(\"SentenceID\", split($\"value\", \"\\\\t\").getItem(6))\n.withColumn(\"Actor1CharOffset\", split($\"value\", \"\\\\t\").getItem(7))\n.withColumn(\"Actor2CharOffset\", split($\"value\", \"\\\\t\").getItem(8))\n.withColumn(\"ActionCharOffset\", split($\"value\", \"\\\\t\").getItem(9))\n.withColumn(\"InRawText\", split($\"value\", \"\\\\t\").getItem(10))\n.withColumn(\"Confidence\", split($\"value\", \"\\\\t\").getItem(11))\n.withColumn(\"MentionDocLen\", split($\"value\", \"\\\\t\").getItem(12))\n.withColumn(\"MentionDocTone\", split($\"value\", \"\\\\t\").getItem(13))\n.withColumn(\"MentionDocTranslationInfo\", split($\"value\", \"\\\\t\").getItem(14))\n.withColumn(\"Extras\", split($\"value\", \"\\\\t\").getItem(15))\n.withColumn(\"Langue_1\", when (col(\"MentionDocTranslationInfo\") === \"\", \":eng\").otherwise(col(\"MentionDocTranslationInfo\")))    /// les lignes suivante concernent la Tramsformation de la colonne MentionDocTranslationInfo\n.withColumn(\"Langue_2\", split($\"Langue_1\", \";\").getItem(0))\n.withColumn(\"Langue\", split($\"Langue_2\", \":\").getItem(1))\n.drop($\"Langue_1\")\n.drop($\"Langue_2\")\n.drop($\"value\")\n//.drop($\"MentionDocTranslationInfo\")  à supprimer une fois le groupe convaincu que la transformation de la colonne fonctionne\n","dateUpdated":"2020-01-16T21:30:58+0000","config":{"tableHide":true,"editorSetting":{"language":"scala","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"mentionRDD_eng: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[231] at flatMap at <console>:55\nmentionRDD_translate: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[233] at flatMap at <console>:56\nmentionDF: org.apache.spark.sql.DataFrame = [GLOBALEVENTID: string, EventTimeDate: string ... 15 more fields]\n"}]},"apps":[],"jobName":"paragraph_1579203573941_241346046","id":"20200111-162803_300481733","dateCreated":"2020-01-16T19:39:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4227","user":"anonymous","dateFinished":"2020-01-16T21:30:49+0000","dateStarted":"2020-01-16T21:30:47+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579205010896_-885932125","id":"20200116-200330_122564667","dateCreated":"2020-01-16T20:03:30+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:5960","text":"mentionDF.select(\"MentionDocTranslationInfo\",\"Langue\").distinct.show()      // piste d'amélioration : trouver ou créer un dico key/value pour remplacer le sigle par la langue full name   . De Mëme pour les pays","dateUpdated":"2020-01-16T21:31:07+0000","dateFinished":"2020-01-16T21:31:21+0000","dateStarted":"2020-01-16T21:31:07+0000","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------------------+------+\n|MentionDocTranslationInfo|Langue|\n+-------------------------+------+\n|     srclc:dan;eng:GT-...|   dan|\n|     srclc:swe;eng:GT-...|   swe|\n|     srclc:ces;eng:Mos...|   ces|\n|     srclc:spa;eng:Mos...|   spa|\n|     srclc:kat;eng:GT-...|   kat|\n|     srclc:tur;eng:GT-...|   tur|\n|     srclc:urd;eng:GT-...|   urd|\n|     srclc:rus;eng:GT-...|   rus|\n|     srclc:est;eng:Mos...|   est|\n|     srclc:som;eng:GT-...|   som|\n|     srclc:ita;eng:GT-...|   ita|\n|     srclc:nld;eng:GT-...|   nld|\n|     srclc:lit;eng:GT-...|   lit|\n|     srclc:bul;eng:GT-...|   bul|\n|     srclc:ben;eng:GT-...|   ben|\n|     srclc:tel;eng:GT-...|   tel|\n|     srclc:spa;eng:GT-...|   spa|\n|     srclc:hrv;eng:GT-...|   hrv|\n|     srclc:fas;eng:GT-...|   fas|\n|     srclc:fra;eng:GT-...|   fra|\n+-------------------------+------+\nonly showing top 20 rows\n\n"}]}},{"text":"// on réduit d'abord le nombre de colonnes sur chaque DF avant d'effectuer le join pour améliorer les performances \n\nval eventDF_selected  = eventDF.select(\"GLOBALEVENTID\",\"Day\",\"MonthYear\",\"Year\",\"Actor1Name\",\"Actor1CountryCode\",\"Actor2Name\",\"Actor2CountryCode\",\"NumMentions\",\"NumArticles\",\"AvgTone\",\"ActionGeo_FullName\",\"ActionGeo_CountryCode\") \n\nval gkgDF_selected = gkgDF.select(\"GKGRECORDID\",\"DATE\",\"SourceCommonName\",\"DocumentIdentifier\",\"Themes\",\"Locations\",\"Persons\",\"Organizations\",\"V2Tone\",\"TranslationInfo\")   \n\nval mentionDF_selected = mentionDF.select(\"GLOBALEVENTID\",\"EventTimeDate\",\"MentionTimeDate\",\"MentionSourceName\",\"MentionDocTone\",\"MentionDocTranslationInfo\",\"Langue\")\n\n \n//JOIN eventDF_selected with mentionDF_selected ON GLOBALEVENTID   //\nval event_mention_DF = eventDF_selected.join(mentionDF_selected,\"GlobalEventID\").cache()                                                                               // is the .cache() effective here? TBC","dateUpdated":"2020-01-16T21:31:37+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"eventDF_selected: org.apache.spark.sql.DataFrame = [GLOBALEVENTID: string, Day: string ... 11 more fields]\ngkgDF_selected: org.apache.spark.sql.DataFrame = [GKGRECORDID: string, DATE: string ... 8 more fields]\nmentionDF_selected: org.apache.spark.sql.DataFrame = [GLOBALEVENTID: string, EventTimeDate: string ... 5 more fields]\nevent_mention_DF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [GLOBALEVENTID: string, Day: string ... 17 more fields]\n"}]},"apps":[],"jobName":"paragraph_1579203573942_242500293","id":"20200111-163126_611491370","dateCreated":"2020-01-16T19:39:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4228","user":"anonymous","dateFinished":"2020-01-16T21:31:38+0000","dateStarted":"2020-01-16T21:31:37+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579208426214_344264626","id":"20200116-210026_1719925702","dateCreated":"2020-01-16T21:00:26+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6956","text":"//essai avec un filtre\nevent_mention_DF.filter(\"ActionGeo_CountryCode == 'US'\").distinct.show()","dateUpdated":"2020-01-16T21:00:53+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579207061977_700241679","id":"20200116-203741_1375339315","dateCreated":"2020-01-16T20:37:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6337","text":"%md\n### REQUETES","dateUpdated":"2020-01-16T20:41:36+0000","dateFinished":"2020-01-16T20:41:36+0000","dateStarted":"2020-01-16T20:41:36+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>REQUETES</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579207274328_38179122","id":"20200116-204114_684716828","dateCreated":"2020-01-16T20:41:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6423","text":"%md\n### 1) afficher le nombre d’articles/évènements qu’il y a eu pour chaque triplet (jour, pays de l’évènement, langue de l’article).","dateUpdated":"2020-01-16T20:42:35+0000","dateFinished":"2020-01-16T20:42:35+0000","dateStarted":"2020-01-16T20:42:35+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>1) afficher le nombre d’articles/évènements qu’il y a eu pour chaque triplet (jour, pays de l’évènement, langue de l’article).</h3>\n</div>"}]}},{"text":"val question1Df = event_mention_DF\n.filter($\"ActionGeo_CountryCode\" !== \"\")\n.groupBy(\"ActionGeo_CountryCode\", \"Day\", \"Langue\")\n.count()\n\n\nval question1DfFinal = question1Df.select(\"Day\",\"ActionGeo_CountryCode\",\"Langue\",\"count\")\n.withColumnRenamed(\"Day\", \"jour\")\n.withColumnRenamed(\"ActionGeo_CountryCode\", \"pays\")\n.withColumnRenamed(\"Langue\", \"langue_article\")\n.withColumnRenamed(\"count\", \"nombre_article\")\n.sort($\"jour\".asc)                                                                                                              // WHY SEVERAL DAY ?? I thought we only had one day of data\n\nquestion1DfFinal.show()","dateUpdated":"2020-01-16T21:51:19+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\nquestion1Df: org.apache.spark.sql.DataFrame = [ActionGeo_CountryCode: string, Day: string ... 2 more fields]\nquestion1DfFinal: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [jour: string, pays: string ... 2 more fields]\n+--------+----+--------------+--------------+\n|    jour|pays|langue_article|nombre_article|\n+--------+----+--------------+--------------+\n|20081203|  AS|           eng|             1|\n|20081203|  GM|           eng|             1|\n|20081203|  IT|           eng|             1|\n|20081203|  CH|           eng|             1|\n|20081203|  SP|           eng|             1|\n|20081203|  SY|           eng|             1|\n|20081203|  IT|           ita|             4|\n|20081203|  UK|           eng|            16|\n|20081203|  UP|           eng|             1|\n|20081203|  KU|           eng|             1|\n|20081203|  US|           eng|            12|\n|20081203|  IN|           eng|             1|\n|20171201|  KS|           deu|             4|\n|20171201|  JA|           rus|            24|\n|20171201|  BA|           eng|             3|\n|20171201|  AU|           eng|            10|\n|20171201|  RO|           ron|             4|\n|20171201|  SP|           spa|            28|\n|20171201|  FR|           kor|             4|\n|20171201|  GT|           spa|             4|\n+--------+----+--------------+--------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1579203573945_239807051","id":"20200114-152256_1289708062","dateCreated":"2020-01-16T19:39:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4232","user":"anonymous","dateFinished":"2020-01-16T21:50:34+0000","dateStarted":"2020-01-16T21:50:28+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579209002948_1869449782","id":"20200116-211002_733855943","dateCreated":"2020-01-16T21:10:02+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7147","text":"//CASSANDRA\nquestion1DfFinal.write.option(\"header\", \"true\").csv(\"/zeppelin/tmp/question_1_clean.csv\")\n//question1DfFinal.write.cassandraFormat(\"table\", \"gdelt\").save()","dateUpdated":"2020-01-16T21:53:27+0000","dateFinished":"2020-01-16T21:53:36+0000","dateStarted":"2020-01-16T21:53:27+0000","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579207379360_587721501","id":"20200116-204259_1718312652","dateCreated":"2020-01-16T20:42:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6523","text":"%md \n### 2) Pour un pays donné en paramètre, affichez les évènements qui y ont eu place triées par le nombre de mentions (tri décroissant); permettez une agrégation par jour/mois/année","dateUpdated":"2020-01-16T20:43:14+0000","dateFinished":"2020-01-16T20:43:14+0000","dateStarted":"2020-01-16T20:43:14+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>2) Pour un pays donné en paramètre, affichez les évènements qui y ont eu place triées par le nombre de mentions (tri décroissant); permettez une agrégation par jour/mois/année</h3>\n</div>"}]}},{"text":"//choisir soit ActionGeo_CountryCode soit ActionGeo_FullName\n// Df avec colonne dans l'ordre\nval question2Df = event_mention_DF.select(\"ActionGeo_CountryCode\",\"Day\",\"MonthYear\",\"Year\",\"GLOBALEVENTID\",\"MentionTimeDate\")   //peut être que MentionTimeDate n'est pas nécessaire mais pratique pour distinguer les mentions pour un même event\n.filter($\"ActionGeo_CountryCode\" !== \"\")\n.groupBy(\"ActionGeo_CountryCode\",\"Day\",\"MonthYear\",\"Year\",\"GLOBALEVENTID\")\n.count()\n\n\nval question2DfFinal = question2Df\n.withColumnRenamed(\"Day\", \"jour\")\n.withColumnRenamed(\"ActionGeo_CountryCode\", \"pays\")\n.withColumnRenamed(\"Langue\", \"langue_article\")\n.withColumnRenamed(\"count\", \"nombre_articles\")\n.sort($\"nombre_articles\".desc) \n\n\nquestion2DfFinal.show()","dateUpdated":"2020-01-16T21:53:07+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"warning: there was one deprecation warning; re-run with -deprecation for details\nquestion2Df: org.apache.spark.sql.DataFrame = [ActionGeo_CountryCode: string, Day: string ... 4 more fields]\nquestion2DfFinal: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [pays: string, jour: string ... 4 more fields]\n+----+--------+---------+----+-------------+--------------+\n|pays|    jour|MonthYear|Year|GLOBALEVENTID|nombre_article|\n+----+--------+---------+----+-------------+--------------+\n|  MX|20181201|   201812|2018|    806769030|          2118|\n|  AR|20181201|   201812|2018|    806754807|          1593|\n|  FR|20181201|   201812|2018|    806805339|          1424|\n|  US|20181201|   201812|2018|    806757863|          1206|\n|  US|20181201|   201812|2018|    806800959|          1181|\n|  US|20181201|   201812|2018|    806754650|          1109|\n|  FR|20181201|   201812|2018|    806836065|          1098|\n|  US|20181201|   201812|2018|    806756120|          1096|\n|  IS|20181201|   201812|2018|    806764378|          1048|\n|  US|20181201|   201812|2018|    806757704|          1027|\n|  US|20181201|   201812|2018|    806757889|          1004|\n|  IS|20181201|   201812|2018|    806764116|           964|\n|  US|20181201|   201812|2018|    806757901|           933|\n|  AR|20181201|   201812|2018|    806754811|           892|\n|  FR|20181201|   201812|2018|    806857971|           876|\n|  FR|20181201|   201812|2018|    806788279|           856|\n|  US|20181201|   201812|2018|    806757864|           826|\n|  IS|20181201|   201812|2018|    806763423|           786|\n|  FR|20181201|   201812|2018|    806781055|           778|\n|  FR|20181201|   201812|2018|    806862749|           766|\n+----+--------+---------+----+-------------+--------------+\nonly showing top 20 rows\n\n"}]},"apps":[],"jobName":"paragraph_1579203573947_240576549","id":"20200115-201647_183260547","dateCreated":"2020-01-16T19:39:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4234","user":"anonymous","dateFinished":"2020-01-16T21:52:47+0000","dateStarted":"2020-01-16T21:52:44+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579211591615_-856235141","id":"20200116-215311_198608266","dateCreated":"2020-01-16T21:53:11+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7843","text":"//CASSANDRA\nquestion2DfFinal.write.option(\"header\", \"true\").csv(\"/zeppelin/tmp/question_2_clean.csv\")","dateUpdated":"2020-01-16T21:54:40+0000","dateFinished":"2020-01-16T21:54:45+0000","dateStarted":"2020-01-16T21:54:40+0000","results":{"code":"SUCCESS","msg":[]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579210979051_1513011360","id":"20200116-214259_1993738308","dateCreated":"2020-01-16T21:42:59+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7571","text":"//test\n//requete :  remplacer IN par un autre pays,   // count number of articles per globaleventid\nval q2= question2Df.filter(\"ActionGeo_CountryCode == 'IN'\").groupBy(\"GLOBALEVENTID\",\"Day\").agg(\n    expr(\"count(MentionTimeDate) as Nombre_Article\")).sort($\"Nombre_Article\".desc) \n\n//reordonner les colonnes\nval test_ordered = q2.select(\"GLOBALEVENTID\",\"Nombre_Article\",\"Day\")\ntest_ordered.show\n","dateUpdated":"2020-01-16T21:43:19+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579207424640_-993935255","id":"20200116-204344_362751402","dateCreated":"2020-01-16T20:43:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6610","text":"%md\n### 3) Pour une source de donnés passée en paramètre (gkg.SourceCommonName) affichez les thèmes, personnes, lieux dont les articles de cette sources parlent ainsi que le nombre d’articles et le ton moyen des articles (pour chaque thème/personne/lieu); permettez une agrégation par jour/mois/année.","dateUpdated":"2020-01-16T20:44:10+0000","dateFinished":"2020-01-16T20:44:10+0000","dateStarted":"2020-01-16T20:44:10+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>3) Pour une source de donnés passée en paramètre (gkg.SourceCommonName) affichez les thèmes, personnes, lieux dont les articles de cette sources parlent ainsi que le nombre d’articles et le ton moyen des articles (pour chaque thème/personne/lieu); permettez une agrégation par jour/mois/année.</h3>\n</div>"}]}},{"text":"","dateUpdated":"2020-01-16T21:03:53+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579203573947_240576549","id":"20200115-212724_1916326265","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4235"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579208103979_1069674478","id":"20200116-205503_1066054129","dateCreated":"2020-01-16T20:55:03+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6770","text":"%md \n### 4) dresser la cartographie des relations entre les pays d’après le ton des articles : pour chaque paire (pays1, pays2), calculer le nombre d’article, le ton moyen (aggrégations sur Année/Mois/Jour, filtrage par pays ou carré de coordonnées)","dateUpdated":"2020-01-16T20:57:32+0000","dateFinished":"2020-01-16T20:57:32+0000","dateStarted":"2020-01-16T20:57:32+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>4) dresser la cartographie des relations entre les pays d’après le ton des articles : pour chaque paire (pays1, pays2), calculer le nombre d’article, le ton moyen (aggrégations sur Année/Mois/Jour, filtrage par pays ou carré de coordonnées)</h3>\n</div>"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579208104915_1017348628","id":"20200116-205504_640282449","dateCreated":"2020-01-16T20:55:04+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6826"},{"text":"%md A vous de jouer ! Utilisez la documentation GDELT(https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/) et commencez a explorer les donnees via les API Spark.","dateUpdated":"2020-01-16T19:39:33+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>A vous de jouer ! Utilisez la documentation GDELT(<a href=\"https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/\">https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/</a>) et commencez a explorer les donnees via les API Spark.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1579203573948_238652804","id":"20171218-084519_765381887","dateCreated":"2020-01-16T19:39:33+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:4236"},{"text":"%md\n","user":"anonymous","dateUpdated":"2020-01-16T20:55:02+0000","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1579208102124_304408916","id":"20200116-205502_1328365913","dateCreated":"2020-01-16T20:55:02+0000","status":"READY","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6714"}],"name":"gdeltExploration (Local with Docker MasterfileList + TRANSLATION)","id":"2F11QDYBU","angularObjects":{"2EYBWTWJ8:shared_process":[],"2EZW6TGYF:shared_process":[],"2EYECXRFM:shared_process":[],"2EZTG5HZW:shared_process":[],"2EYHDXX12:shared_process":[],"2F13ZEF7T:shared_process":[],"2EWTHCS4T:shared_process":[],"2EY6GQJF6:shared_process":[],"2EXD868VC:shared_process":[],"2EYGQ28GP:shared_process":[],"2EZVQA2BK:shared_process":[],"2EZPXP49N:shared_process":[],"2EYPZC7T9:shared_process":[],"2EZQQ343U:shared_process":[],"2F1KWKXMB:shared_process":[],"2EXT1DUUR:shared_process":[],"2F1E6V8Z7:shared_process":[],"2F11EV11B:shared_process":[],"2EWTCC5W9:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}