{"paragraphs":[{"text":"%md\n## Exploration des donnees GDELT via Spark\nDans ce notebook nous allons commencer a explorer les donnees GDELT qu'on a stoque sur S3","user":"anonymous","dateUpdated":"2018-12-12T10:28:53+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544610203617_1698407308","id":"20181212-102323_67420128","dateCreated":"2018-12-12T10:23:23+0000","dateStarted":"2018-12-12T10:28:53+0000","dateFinished":"2018-12-12T10:28:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1474","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Exploration des donnees GDELT via Spark</h2>\n<p>Dans ce notebook nous allons commencer a explorer les donnees GDELT qu&rsquo;on a stoque sur S3</p>\n</div>"}]}},{"text":"sc.hadoopConfiguration.set(\"fs.s3a.access.key\", \"TODO\") // mettre votre ID du fichier credentials.csv\nsc.hadoopConfiguration.set(\"fs.s3a.secret.key\", \"TODO\") // mettre votre secret du fichier credentials.csv\n","user":"anonymous","dateUpdated":"2018-12-12T10:29:39+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1544608228911_-83390831","id":"20171217-230735_1688540039","dateCreated":"2018-12-12T09:50:28+0000","dateStarted":"2018-12-12T10:28:31+0000","dateFinished":"2018-12-12T10:28:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1475"},{"text":"%md Les fichiers sont stoquees compresses, on a besoin d'un bout de code pour les decompresser en parallel sur les workers au fur et a mesure qu'on les lit depuis S3:","user":"anonymous","dateUpdated":"2018-12-12T10:28:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Les fichiers sont stoquees compresses, on a besoin d&rsquo;un bout de code pour les decompresser en parallel sur les workers au fur et a mesure qu&rsquo;on les lit depuis S3:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1544610209001_-1619948425","id":"20181212-102329_808049084","dateCreated":"2018-12-12T10:23:29+0000","dateStarted":"2018-12-12T10:28:32+0000","dateFinished":"2018-12-12T10:28:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1476"},{"text":"import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\n// 20181201000000.export.CSV.zip\nval textRDD = sc.binaryFiles(\"s3a://john-doe-telecom-gdelt2018/20181201[0-9]*.export.CSV.zip\"). // charger quelques fichers via une regex\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) =>\n          val zis = new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ != null).\n                flatMap { _ =>\n                    val br = new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ != null)\n                }\n    }\ntextRDD.take(1)\n","user":"anonymous","dateUpdated":"2018-12-12T10:28:32+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"fontSize":9},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1544608228919_-256809170","id":"20171217-232457_1732696781","dateCreated":"2018-12-12T09:50:28+0000","dateStarted":"2018-12-12T10:28:32+0000","dateFinished":"2018-12-12T10:28:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1477","runtimeInfos":{"jobUrl":{"propertyName":"jobUrl","label":"SPARK JOB","tooltip":"View in Spark web UI","group":"spark","values":["http://ip-172-31-27-188.ec2.internal:4040/jobs/job?id=10"],"interpreterSettingId":"spark"}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\ntextRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[69] at flatMap at <console>:77\nres54: Array[String] = Array(806754250\t20171201\t201712\t2017\t2017.9068\t\t\t\t\t\t\t\t\t\t\tUSA\tUNITED STATES\tUSA\t\t\t\t\t\t\t\t1\t100\t100\t10\t3\t-5.0\t4\t1\t4\t-0.66666666666667\t0\t\t\t\t\t\t\t\t3\tNew Haven, Connecticut, United States\tUS\tUSCT\t\t41.3082\t-72.9282\t209231\t3\tNew Haven, Connecticut, United States\tUS\tUSCT\t\t41.3082\t-72.9282\t209231\t20181201000000\thttps://bismarcktribune.com/news/national/the-latest-immigrant-s-supporters-end-courthouse-protest/article_76d71ef6-d0e0-5e02-ab72-4c8a0d31778e.html)\n"}]}},{"text":"%md A vous de jouer ! Utilisez la documentation GDELT(https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/) et commencez a explorer les donnees via les API Spark.","user":"anonymous","dateUpdated":"2018-12-12T10:28:35+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"fontSize":9,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>A vous de jouer ! Utilisez la documentation GDELT(<a href=\"https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/\">https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/</a>) et commencez a explorer les donnees via les API Spark.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1544608228920_-1190303486","id":"20171218-084519_765381887","dateCreated":"2018-12-12T09:50:28+0000","dateStarted":"2018-12-12T10:28:35+0000","dateFinished":"2018-12-12T10:28:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:1478"}],"name":"gdeltExploration","id":"2DX6G58XU","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"sh:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}